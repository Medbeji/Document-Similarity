{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T12:36:02.224588Z",
     "start_time": "2020-08-26T12:35:56.408836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-26 14:35:59 - Load pretrained SentenceTransformer: distilbert-base-nli-stsb-mean-tokens\n",
      "2020-08-26 14:35:59 - Did not find a '/' or '\\' in the name. Assume to download model from server.\n",
      "2020-08-26 14:35:59 - Load SentenceTransformer from folder: /Users/medbeji/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip\n",
      "2020-08-26 14:35:59 - loading configuration file /Users/medbeji/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_Transformer/config.json\n",
      "2020-08-26 14:35:59 - Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "2020-08-26 14:35:59 - loading weights file /Users/medbeji/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_Transformer/pytorch_model.bin\n",
      "2020-08-26 14:36:02 - All model checkpoint weights were used when initializing DistilBertModel.\n",
      "\n",
      "2020-08-26 14:36:02 - All the weights of DistilBertModel were initialized from the model checkpoint at /Users/medbeji/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_Transformer.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use DistilBertModel for predictions without further training.\n",
      "2020-08-26 14:36:02 - loading configuration file /Users/medbeji/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_Transformer/config.json\n",
      "2020-08-26 14:36:02 - Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "2020-08-26 14:36:02 - Model name '/Users/medbeji/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_Transformer' not found in model shortcut name list (distilbert-base-uncased, distilbert-base-uncased-distilled-squad, distilbert-base-cased, distilbert-base-cased-distilled-squad, distilbert-base-german-cased, distilbert-base-multilingual-cased). Assuming '/Users/medbeji/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_Transformer' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "2020-08-26 14:36:02 - Didn't find file /Users/medbeji/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_Transformer/added_tokens.json. We won't load it.\n",
      "2020-08-26 14:36:02 - Didn't find file /Users/medbeji/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_Transformer/tokenizer.json. We won't load it.\n",
      "2020-08-26 14:36:02 - loading file /Users/medbeji/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_Transformer/vocab.txt\n",
      "2020-08-26 14:36:02 - loading file None\n",
      "2020-08-26 14:36:02 - loading file /Users/medbeji/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_Transformer/special_tokens_map.json\n",
      "2020-08-26 14:36:02 - loading file /Users/medbeji/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_distilbert-base-nli-stsb-mean-tokens.zip/0_Transformer/tokenizer_config.json\n",
      "2020-08-26 14:36:02 - loading file None\n",
      "2020-08-26 14:36:02 - Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This basic example loads a pre-trained model from the web and uses it to\n",
    "generate sentence embeddings for a given list of sentences.\n",
    "\"\"\"\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, LoggingHandler\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Just some code to print debug information to stdout\n",
    "np.set_printoptions(threshold=100)\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "# /print debug information to stdout\n",
    "\n",
    "\n",
    "# Load pre-trained Sentence Transformer Model (based on DistilBERT). It will be downloaded automatically\n",
    "model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T12:36:02.547063Z",
     "start_time": "2020-08-26T12:36:02.230455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-26 14:36:02 - Start tokenization 3 sentences\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269f3d7b12d94f5a8bc9ff9bc0db86ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Batches', max=1, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Embed a list of sentences\n",
    "sentences = ['Coronavirus en France : 22 nouveaux décès, le taux de positivité progresse encore',\n",
    "             'Port du masque obligatoire à Toulouse : il fallait \"passer à autre chose de beaucoup plus fort\", affirme le maire Jean-Luc Moudenc',\n",
    "             'Coronavirus : la Tunisie impose le port obligatoire du masque']\n",
    "sentence_embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T12:36:02.563507Z",
     "start_time": "2020-08-26T12:36:02.551674Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance as dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T12:36:02.591470Z",
     "start_time": "2020-08-26T12:36:02.569387Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine distance between : \n",
      " - Coronavirus en France : 22 nouveaux décès, le taux de positivité progresse encore \n",
      " - Coronavirus en France : 22 nouveaux décès, le taux de positivité progresse encore \n",
      "is equal to : 1.0\n",
      "The cosine distance between : \n",
      " - Coronavirus en France : 22 nouveaux décès, le taux de positivité progresse encore \n",
      " - Port du masque obligatoire à Toulouse : il fallait \"passer à autre chose de beaucoup plus fort\", affirme le maire Jean-Luc Moudenc \n",
      "is equal to : 0.43000683188438416\n",
      "The cosine distance between : \n",
      " - Coronavirus en France : 22 nouveaux décès, le taux de positivité progresse encore \n",
      " - Coronavirus : la Tunisie impose le port obligatoire du masque \n",
      "is equal to : 0.5688125491142273\n",
      "The cosine distance between : \n",
      " - Port du masque obligatoire à Toulouse : il fallait \"passer à autre chose de beaucoup plus fort\", affirme le maire Jean-Luc Moudenc \n",
      " - Coronavirus en France : 22 nouveaux décès, le taux de positivité progresse encore \n",
      "is equal to : 0.43000683188438416\n",
      "The cosine distance between : \n",
      " - Port du masque obligatoire à Toulouse : il fallait \"passer à autre chose de beaucoup plus fort\", affirme le maire Jean-Luc Moudenc \n",
      " - Port du masque obligatoire à Toulouse : il fallait \"passer à autre chose de beaucoup plus fort\", affirme le maire Jean-Luc Moudenc \n",
      "is equal to : 1.0\n",
      "The cosine distance between : \n",
      " - Port du masque obligatoire à Toulouse : il fallait \"passer à autre chose de beaucoup plus fort\", affirme le maire Jean-Luc Moudenc \n",
      " - Coronavirus : la Tunisie impose le port obligatoire du masque \n",
      "is equal to : 0.4609462320804596\n",
      "The cosine distance between : \n",
      " - Coronavirus : la Tunisie impose le port obligatoire du masque \n",
      " - Coronavirus en France : 22 nouveaux décès, le taux de positivité progresse encore \n",
      "is equal to : 0.5688125491142273\n",
      "The cosine distance between : \n",
      " - Coronavirus : la Tunisie impose le port obligatoire du masque \n",
      " - Port du masque obligatoire à Toulouse : il fallait \"passer à autre chose de beaucoup plus fort\", affirme le maire Jean-Luc Moudenc \n",
      "is equal to : 0.4609462320804596\n",
      "The cosine distance between : \n",
      " - Coronavirus : la Tunisie impose le port obligatoire du masque \n",
      " - Coronavirus : la Tunisie impose le port obligatoire du masque \n",
      "is equal to : 1.0\n"
     ]
    }
   ],
   "source": [
    "# The result is a list of sentence embeddings as numpy arrays\n",
    "for sentence, embedding in zip(sentences, sentence_embeddings):\n",
    "    for sentence_1, embedding_1 in zip(sentences, sentence_embeddings):\n",
    "        print('The cosine distance between : \\n - {} \\n - {} '.format(sentence, sentence_1))\n",
    "        print('is equal to : {}'.format(1 - dst.cosine(embedding, embedding_1)))\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
